{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import model_selection, metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Performing grid search\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('./../Data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 15)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_length(df):\n",
    "    df[\"num_photos\"] = df[\"photos\"].apply(len)\n",
    "    df[\"num_features\"] = df[\"features\"].apply(len)\n",
    "    df[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.strip().split(\" \")))\n",
    "    return(df)\n",
    "def calculate_date(df): \n",
    "    df[\"created\"] = pd.to_datetime(df[\"created\"])\n",
    "    df[\"created_year\"] = df[\"created\"].dt.year\n",
    "    df[\"created_month\"] = df[\"created\"].dt.month\n",
    "    df[\"created_day\"] = df[\"created\"].dt.day\n",
    "    df[\"created_hour\"] = df[\"created\"].dt.hour\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 22)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = calculate_length(train)\n",
    "train = calculate_date(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode certain categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64'), dtype('O'), dtype('<M8[ns]')], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [x for x in train.select_dtypes(include=['int64', 'float64']).columns if x not in ['listing_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'bathrooms',\n",
       " u'bedrooms',\n",
       " u'latitude',\n",
       " u'longitude',\n",
       " u'price',\n",
       " 'num_photos',\n",
       " 'num_features',\n",
       " 'num_description_words',\n",
       " 'created_year',\n",
       " 'created_month',\n",
       " 'created_day',\n",
       " 'created_hour']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'building_id', u'description', u'display_address', u'features',\n",
       "       u'interest_level', u'manager_id', u'photos', u'street_address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encode some categorical variables (different from one-hot encoding!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LabelEncoder(df, columns, features, append=False):\n",
    "    for cols in columns:\n",
    "        label = preprocessing.LabelEncoder()\n",
    "        label.fit(df[cols].values)\n",
    "        df[cols] = label.transform(df[cols].values)\n",
    "        if append:\n",
    "            features.append(cols)\n",
    "    return df, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "train, features = LabelEncoder(train, categorical, features, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        2431\n",
       "10000     5862\n",
       "100004    5806\n",
       "100007    1201\n",
       "100013       0\n",
       "Name: building_id, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.building_id.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tf-idf matrix from text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[],\n",
       "       [u'Doorman', u'Elevator', u'Fitness Center', u'Cats Allowed', u'Dogs Allowed'],\n",
       "       [u'Laundry In Building', u'Dishwasher', u'Hardwood Floors', u'Pets Allowed Case by Case'],\n",
       "       ...,\n",
       "       [u'Doorman', u'Elevator', u'Pre-War', u'Dogs Allowed', u'Cats Allowed'],\n",
       "       [u'Doorman', u'Elevator', u'Pre-War', u'Dogs Allowed', u'Cats Allowed'],\n",
       "       [u'Hardwood Floors']], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['features'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train['features'] = train[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "train['features'] = train['features'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', u'Doorman,Elevator,Fitness Center,Cats Allowed,Dogs Allowed',\n",
       "       u'Laundry In Building,Dishwasher,Hardwood Floors,Pets Allowed Case by Case',\n",
       "       ..., u'Doorman,Elevator,Pre-War,Dogs Allowed,Cats Allowed',\n",
       "       u'Doorman,Elevator,Pre-War,Dogs Allowed,Cats Allowed',\n",
       "       u'Hardwood Floors'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['features'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = text.CountVectorizer(stop_words='english', max_features=200, ngram_range=(1,2))\n",
    "tr_sparse = tfidf.fit_transform(train[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49352, 200), (49352, 16))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_sparse.shape, train[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49352, 216), (49352,))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = sparse.hstack([train[features], tr_sparse]).tocsr()\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.5   ,   3.    ,  40.7145, ...,   0.    ,   0.    ,   0.    ])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=100)\n",
    "train_X.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_description_words</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>display_address</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>3000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>6544</td>\n",
       "      <td>1239</td>\n",
       "      <td>2431</td>\n",
       "      <td>14074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>5465</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4506</td>\n",
       "      <td>1583</td>\n",
       "      <td>5862</td>\n",
       "      <td>14195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>2850</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7387</td>\n",
       "      <td>2965</td>\n",
       "      <td>5806</td>\n",
       "      <td>5876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms  latitude  longitude  price  num_photos  \\\n",
       "10            1.5         3   40.7145   -73.9425   3000           5   \n",
       "10000         1.0         2   40.7947   -73.9667   5465          11   \n",
       "100004        1.0         1   40.7388   -74.0018   2850           8   \n",
       "\n",
       "        num_features  num_description_words  created_year  created_month  \\\n",
       "10                 0                     94          2016              6   \n",
       "10000              5                      1          2016              6   \n",
       "100004             4                     93          2016              4   \n",
       "\n",
       "        created_day  created_hour  display_address  manager_id  building_id  \\\n",
       "10               24             7             6544        1239         2431   \n",
       "10000            12            12             4506        1583         5862   \n",
       "100004           17             3             7387        2965         5806   \n",
       "\n",
       "        street_address  \n",
       "10               14074  \n",
       "10000            14195  \n",
       "100004            5876  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[features].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgbfit(model, dtrain, output, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = model.get_xgb_params()\n",
    "        xgb_param['num_class'] = 3\n",
    "        \n",
    "        xgtrain = xgb.DMatrix(dtrain, label=output)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=model.get_params()['n_estimators'], nfold=cv_folds, \\\n",
    "                          metrics='mlogloss', early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "        model.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the model algorithm on the data\n",
    "    model.fit(dtrain, output, eval_metric='mlogloss')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = model.predict(dtrain)\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    #print \"R-Square: %.3f\" % metrics.r2_score(output, dtrain_predictions)\n",
    "    print \"Log Loss : %.3f\" % np.sqrt(metrics.log_loss(output, dtrain_predictions, labels=[0,1,2]))\n",
    "    print \"Optimal CV Score:\" \n",
    "    print(cvresult.iloc[len(cvresult)-1,:])\n",
    "    print \"Optimal iteration: %d\" %(len(cvresult)-1)\n",
    "    #print \"Cross Validation Result: \"\n",
    "    #print(cvresult)\n",
    "    \n",
    "    plt.figure()\n",
    "    cvresult.loc[:,[\"test-mlogloss\", \"train-mlogloss\"]].plot()\n",
    "    return (len(cvresult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'bathrooms',\n",
       " u'bedrooms',\n",
       " u'latitude',\n",
       " u'longitude',\n",
       " u'price',\n",
       " 'num_photos',\n",
       " 'num_features',\n",
       " 'num_description_words',\n",
       " 'created_year',\n",
       " 'created_month',\n",
       " 'created_day',\n",
       " 'created_hour',\n",
       " 'display_address',\n",
       " 'manager_id',\n",
       " 'building_id',\n",
       " 'street_address']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes in labels is different from that in y_pred. Classes found in labels: [0 1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-ac3f8753b8ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m  \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m  seed=189)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgbfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-192-57a338540908>\u001b[0m in \u001b[0;36mxgbfit\u001b[0;34m(model, dtrain, output, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\nModel Report\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print \"R-Square: %.3f\" % metrics.r2_score(output, dtrain_predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Log Loss : %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Optimal CV Score:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             raise ValueError('The number of classes in labels is different '\n\u001b[1;32m   1657\u001b[0m                              \u001b[0;34m'from that in y_pred. Classes found in '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m                              'labels: {0}'.format(lb.classes_))\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;31m# Renormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes in labels is different from that in y_pred. Classes found in labels: [0 1 2]"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=6,\n",
    " min_child_weight=1,\n",
    " #gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective='multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=189)\n",
    "n_estimators = xgbfit(xgb1, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = True\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=30)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.04231\ttest-mlogloss:1.04335\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\ttrain-mlogloss:0.988808\ttest-mlogloss:0.991342\n",
      "[2]\ttrain-mlogloss:0.9447\ttest-mlogloss:0.947949\n",
      "[3]\ttrain-mlogloss:0.905032\ttest-mlogloss:0.909496\n",
      "[4]\ttrain-mlogloss:0.873738\ttest-mlogloss:0.879315\n",
      "[5]\ttrain-mlogloss:0.8452\ttest-mlogloss:0.851965\n",
      "[6]\ttrain-mlogloss:0.821483\ttest-mlogloss:0.828979\n",
      "[7]\ttrain-mlogloss:0.798081\ttest-mlogloss:0.806763\n",
      "[8]\ttrain-mlogloss:0.779337\ttest-mlogloss:0.789054\n",
      "[9]\ttrain-mlogloss:0.763191\ttest-mlogloss:0.773825\n",
      "[0]\ttrain-mlogloss:1.04218\ttest-mlogloss:1.04306\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\ttrain-mlogloss:0.98889\ttest-mlogloss:0.990589\n",
      "[2]\ttrain-mlogloss:0.944869\ttest-mlogloss:0.947613\n",
      "[3]\ttrain-mlogloss:0.905808\ttest-mlogloss:0.909032\n",
      "[4]\ttrain-mlogloss:0.874403\ttest-mlogloss:0.878286\n",
      "[5]\ttrain-mlogloss:0.846063\ttest-mlogloss:0.85052\n",
      "[6]\ttrain-mlogloss:0.82223\ttest-mlogloss:0.82755\n",
      "[7]\ttrain-mlogloss:0.798562\ttest-mlogloss:0.804737\n",
      "[8]\ttrain-mlogloss:0.780015\ttest-mlogloss:0.78687\n",
      "[9]\ttrain-mlogloss:0.764084\ttest-mlogloss:0.771618\n",
      "[0]\ttrain-mlogloss:1.03727\ttest-mlogloss:1.03705\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\ttrain-mlogloss:0.984484\ttest-mlogloss:0.984005\n",
      "[2]\ttrain-mlogloss:0.944027\ttest-mlogloss:0.943723\n",
      "[3]\ttrain-mlogloss:0.905473\ttest-mlogloss:0.905309\n",
      "[4]\ttrain-mlogloss:0.872217\ttest-mlogloss:0.872441\n",
      "[5]\ttrain-mlogloss:0.84519\ttest-mlogloss:0.845638\n",
      "[6]\ttrain-mlogloss:0.821019\ttest-mlogloss:0.821717\n",
      "[7]\ttrain-mlogloss:0.797477\ttest-mlogloss:0.798822\n",
      "[8]\ttrain-mlogloss:0.777528\ttest-mlogloss:0.779398\n",
      "[9]\ttrain-mlogloss:0.758671\ttest-mlogloss:0.761119\n",
      "[0]\ttrain-mlogloss:1.03672\ttest-mlogloss:1.03845\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\ttrain-mlogloss:0.984133\ttest-mlogloss:0.986989\n",
      "[2]\ttrain-mlogloss:0.943447\ttest-mlogloss:0.94748\n",
      "[3]\ttrain-mlogloss:0.904404\ttest-mlogloss:0.909973\n",
      "[4]\ttrain-mlogloss:0.871004\ttest-mlogloss:0.877333\n",
      "[5]\ttrain-mlogloss:0.843771\ttest-mlogloss:0.850999\n",
      "[6]\ttrain-mlogloss:0.819389\ttest-mlogloss:0.827512\n",
      "[7]\ttrain-mlogloss:0.795706\ttest-mlogloss:0.804846\n",
      "[8]\ttrain-mlogloss:0.77611\ttest-mlogloss:0.785978\n",
      "[9]\ttrain-mlogloss:0.757212\ttest-mlogloss:0.767794\n",
      "[0]\ttrain-mlogloss:1.03689\ttest-mlogloss:1.03828\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\ttrain-mlogloss:0.983946\ttest-mlogloss:0.986643\n",
      "[2]\ttrain-mlogloss:0.943248\ttest-mlogloss:0.946835\n",
      "[3]\ttrain-mlogloss:0.904048\ttest-mlogloss:0.909118\n",
      "[4]\ttrain-mlogloss:0.870739\ttest-mlogloss:0.877103\n",
      "[5]\ttrain-mlogloss:0.843342\ttest-mlogloss:0.850627\n",
      "[6]\ttrain-mlogloss:0.818933\ttest-mlogloss:0.82725\n",
      "[7]\ttrain-mlogloss:0.795661\ttest-mlogloss:0.805011\n",
      "[8]\ttrain-mlogloss:0.776003\ttest-mlogloss:0.78638\n",
      "[9]\ttrain-mlogloss:0.756996\ttest-mlogloss:0.768503\n",
      "cv_scores is: \n",
      "\n",
      "[0.77382506840606557, 0.77161818340597343, 0.76111855259299155, 0.76779423060448582, 0.7685032073548016]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=9594)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])): \n",
    "    # This leads to 5 iterations for 5 splits. \n",
    "    # dev_index has 80% of the data, val_index has 20% since dev_index takes 4/5 splits\n",
    "    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:] #training and validation inputs\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index] #training and validation labels\n",
    "    preds, model = runXGB(dev_X, dev_y, val_X, val_y, num_rounds=10)\n",
    "    cv_scores.append(metrics.log_loss(val_y, preds))\n",
    "print(\"cv_scores is: \\n\") \n",
    "print(cv_scores)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
